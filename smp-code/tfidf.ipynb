{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sub']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "df_tr = pd.read_csv('../data/train/train_labels.txt',sep=u'|',header=None).dropna(1)\n",
    "df_tr.columns = ['uid','sex','age','loc']\n",
    "df_te = pd.read_csv('../data/valid/valid_nolabel.txt',sep=u'|',header=None).dropna(1)\n",
    "df_te.columns = ['uid']\n",
    "df_all = pd.concat([df_tr,df_te],axis=0)\n",
    "\n",
    "df_tr_info = pd.read_csv('../data/train/train_info.txt',sep=u'|',header=None).dropna(1)\n",
    "df_tr_info.columns = ['uid']\n",
    "df_tr_info = df_tr_info.drop_duplicates()\n",
    "df_te_info = pd.read_csv('../data/valid/valid_info.txt',sep=u'|',header=None).dropna(1)\n",
    "df_te_info.columns = ['uid']\n",
    "df_te_info = df_te_info.drop_duplicates()\n",
    "df_info = pd.concat([df_tr_info,df_te_info],axis=0)\n",
    "\n",
    "links = []\n",
    "for i, line in enumerate(open('../data/train/train_links.txt',encoding='UTF-8')):\n",
    "    line = line.split()\n",
    "    row = {'uid':int(line[0]),'fans_cnt':len(line)-1,'fans':' '.join(line[1:])}\n",
    "    links.append(row)\n",
    "df_tr_links = pd.DataFrame(links)\n",
    "df_tr_links = df_tr_links.drop_duplicates()\n",
    "\n",
    "links = []\n",
    "for i, line in enumerate(open('../data/valid/valid_links.txt',encoding='UTF-8')):\n",
    "    line = line.split()\n",
    "    row = {'uid':int(line[0]),'fans_cnt':len(line)-1,'fans':' '.join(line[1:])}\n",
    "    links.append(row)\n",
    "df_te_links = pd.DataFrame(links)\n",
    "df_te_links = df_te_links.drop_duplicates()\n",
    "\n",
    "df_links = pd.concat([df_tr_links,df_te_links],axis=0)\n",
    "\n",
    "status = []\n",
    "for i, line in enumerate(open('../data/train/train_status.txt',encoding='UTF-8')):\n",
    "    \n",
    "    l = re.search(',',line).span()[0]\n",
    "    r = re.search(',',line).span()[1]\n",
    "    row = {'uid':int(line[:l]),'sta':line[r:]}\n",
    "    status.append(row)\n",
    "df_tr_status = pd.DataFrame(status)\n",
    "\n",
    "status = []\n",
    "for i, line in enumerate(open('../data/valid/valid_status.txt',encoding='UTF-8')):\n",
    "    \n",
    "    l = re.search(',',line).span()[0]\n",
    "    r = re.search(',',line).span()[1]\n",
    "    row = {'uid':int(line[:l]),'sta':line[r:]}\n",
    "    status.append(row)\n",
    "df_te_status = pd.DataFrame(status)\n",
    "\n",
    "df_status = pd.concat([df_tr_status,df_te_status],axis=0)\n",
    "\n",
    "df_mge = pd.merge(df_all,df_info,on='uid',how='left')\n",
    "df_mge = pd.merge(df_mge,df_links,on='uid',how='left')\n",
    "df_mge.index = range(len(df_mge))\n",
    "\n",
    "df_status['ret'] = df_status.sta.map(lambda s:int(s.split(',')[0]))\n",
    "df_status['rev'] = df_status.sta.map(lambda s:int(s.split(',')[1]))\n",
    "df_status['src'] = df_status.sta.map(lambda s:s.split(',')[2])\n",
    "df_status['time'] = df_status.sta.map(lambda s:s.split(',')[3])\n",
    "df_status['content'] = df_status.sta.map(lambda s:','.join(s.split(',')[4:]))\n",
    "bag_twts = df_status.groupby('uid')['content'].agg(lambda lst:' '.join(lst))\n",
    "df_mge['bag_twts'] = df_mge.uid.map(bag_twts)\n",
    "df_mge['twts_cnt'] = df_mge.uid.map(df_status.groupby('uid').size())\n",
    "df_mge['twts_ret_mean'] = df_mge.uid.map(df_status.groupby('uid')['ret'].agg('mean'))\n",
    "df_mge['twts_rev_mean'] = df_mge.uid.map(df_status.groupby('uid')['rev'].agg('mean'))\n",
    "\n",
    "d = {'上海': '华东',\n",
    " '云南': '西南',\n",
    " '内蒙古': '华北',\n",
    " '北京': '华北',\n",
    " '台湾': '华东',\n",
    " '吉林': '东北',\n",
    " '四川': '西南',\n",
    " '天津': '华北',\n",
    " '宁夏': '西北',\n",
    " '安徽': '华东',\n",
    " '山东': '华东',\n",
    " '山西': '华北',\n",
    " '广东': '华南',\n",
    " '广西': '华南',\n",
    " '新疆': '西北',\n",
    " '江苏': '华东',\n",
    " '江西': '华东',\n",
    " '河北': '华北',\n",
    " '河南': '华中',\n",
    " '浙江': '华东',\n",
    " '海南': '华南',\n",
    " '湖北': '华中',\n",
    " '湖南': '华中',\n",
    " '澳门': '华南',\n",
    " '甘肃': '西北',\n",
    " '福建': '华东',\n",
    " '西藏': '西南',\n",
    " '贵州': '西南',\n",
    " '辽宁': '东北',\n",
    " '重庆': '西南',\n",
    " '陕西': '西北',\n",
    " '青海': '西北',\n",
    " '香港': '华南',\n",
    " '黑龙江': '东北'}\n",
    "\n",
    "def bin_loc(s):\n",
    "    if pd.isnull(s):\n",
    "        return s\n",
    "    s = s.split(' ')[0]\n",
    "    if s == 'None':\n",
    "        return '华北'\n",
    "    if s == '海外':\n",
    "        return s\n",
    "    return d[s]\n",
    "\n",
    "def bin_age(age):\n",
    "    if pd.isnull(age):\n",
    "        return age\n",
    "    if age <=1979:\n",
    "        return \"-1979\"\n",
    "    elif age<=1989:\n",
    "        return \"1980-1989\"\n",
    "    else:\n",
    "        return \"1990+\"\n",
    "    \n",
    "def mlogloss(yhat,y):\n",
    "    return np.mean([-np.log(yhat[i,_y]) for i,_y in enumerate(y)])\n",
    "def macc(yhat,y):\n",
    "    return np.mean(yhat.argmax(axis=1) == y)\n",
    "\n",
    "def lb_score(yhat_age,y_age,yhat_sex,y_sex,yhat_loc,y_loc):\n",
    "    print('age mlogloss:',mlogloss(yhat_age,y_age))\n",
    "    a1 = macc(yhat_age,y_age)\n",
    "    print('age macc:',a1)\n",
    "    \n",
    "    print('sex mlogloss:',mlogloss(yhat_sex,y_sex))\n",
    "    a2 = macc(yhat_sex,y_sex)\n",
    "    print('sex macc:',a2)\n",
    "    \n",
    "    print('loc mlogloss:',mlogloss(yhat_loc,y_loc))\n",
    "    a3 = macc(yhat_loc,y_loc)\n",
    "    print('loc macc:',a3)\n",
    "    \n",
    "    print('LB score:',0.3*a1+0.2*a2+0.5*a3)\n",
    "\n",
    "df_mge['loc_bin'] = df_mge['loc'].map(bin_loc)\n",
    "df_mge['age_bin'] = df_mge['age'].map(bin_age)\n",
    "\n",
    "age_le = LabelEncoder()\n",
    "y_age = age_le.fit_transform(df_mge.iloc[:3200]['age_bin'])\n",
    "\n",
    "loc_le = LabelEncoder()\n",
    "y_loc = loc_le.fit_transform(df_mge.iloc[:3200]['loc_bin'])\n",
    "\n",
    "sex_le = LabelEncoder()\n",
    "y_sex = sex_le.fit_transform(df_mge.iloc[:3200]['sex'])\n",
    "\n",
    "tokenizer = lambda s:s.split(' ')\n",
    "tfv = TfidfVectorizer(tokenizer=tokenizer,min_df=3,\n",
    "                      norm='l2',use_idf=True,sublinear_tf=True)\n",
    "TR = 3200\n",
    "TE = 1240\n",
    "X_all_sp = tfv.fit_transform(df_mge.bag_twts)\n",
    "X_all_sp = X_all_sp.tocsc()\n",
    "X_sp = X_all_sp[:TR]\n",
    "\n",
    "prds = []\n",
    "stacks = []\n",
    "stacks_name = []\n",
    "task = ['sub']\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "age\n",
      "====================\n",
      "[0]\ttrain-mlogloss:1.04939\n",
      "Will train until train-mlogloss hasn't improved in 25 rounds.\n",
      "[100]\ttrain-mlogloss:0.702715\n",
      "[200]\ttrain-mlogloss:0.58965\n",
      "[300]\ttrain-mlogloss:0.520132\n",
      "[400]\ttrain-mlogloss:0.472281\n",
      "[500]\ttrain-mlogloss:0.437231\n",
      "[600]\ttrain-mlogloss:0.410507\n",
      "[679]\ttrain-mlogloss:0.393533\n"
     ]
    }
   ],
   "source": [
    "###################################################################################\n",
    "label = 'age'\n",
    "print('='*20)\n",
    "print(label)\n",
    "print('='*20)\n",
    "y = y_age\n",
    "params = {\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"booster\": \"gblinear\",\n",
    "    \"num_class\":3,\n",
    "    \"eval_metric\": \"mlogloss\",\n",
    "    \"eta\": 0.0005,\n",
    "    \"silent\": 1,\n",
    "    \"lambda\":0,\n",
    "    \"alpha\": 0.1,\n",
    "}\n",
    "if 'tr' in task:\n",
    "    for tr,va in StratifiedShuffleSplit(y,n_iter=1,test_size=0.2,random_state=1):\n",
    "        X_tr = X_sp[tr]\n",
    "        y_tr = y[tr]\n",
    "        X_va = X_sp[va]\n",
    "        y_va = y[va]\n",
    "        \n",
    "    dtrain = xgb.DMatrix(X_tr, y_tr)\n",
    "    dvalid = xgb.DMatrix(X_va, y_va)\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    bst = xgb.train(params, dtrain, 2000, evals=watchlist,\n",
    "                    early_stopping_rounds=25, verbose_eval=20)\n",
    "if 'sub' in task:\n",
    "    n_iter = 680\n",
    "    dtrain = xgb.DMatrix(X_all_sp[:TR], y)\n",
    "    dtest = xgb.DMatrix(X_all_sp[TR:])\n",
    "\n",
    "    watchlist = [(dtrain, 'train')]\n",
    "    bst = xgb.train(params, dtrain, n_iter, evals=watchlist,\n",
    "                    early_stopping_rounds=25, verbose_eval=100)\n",
    "\n",
    "    prds.append(bst.predict(dtest))\n",
    "if 'stack' in task:\n",
    "    n_iter = 680\n",
    "    n = 5\n",
    "    num_class = 3\n",
    "    stack_tr = np.zeros((TR,num_class))\n",
    "    stack_te = np.zeros((TE,num_class))\n",
    "    dtest = xgb.DMatrix(X_all_sp[TR:])\n",
    "    for i,(tr,va) in enumerate(StratifiedKFold(y,n_folds=n)):\n",
    "        print('stack:%d/%d'%(i+1,n))\n",
    "        dtr = xgb.DMatrix(X_sp[tr],y[tr])\n",
    "        dva = xgb.DMatrix(X_sp[va],y[va])\n",
    "        bst = xgb.train(params, dtr, n_iter)\n",
    "        stack_tr[va] = bst.predict(dva)\n",
    "        stack_te += bst.predict(dtest)\n",
    "    stack_te /= n\n",
    "    stack = np.vstack([stack_tr,stack_te])\n",
    "    stacks.append(stack)\n",
    "    stacks_name += ['%s_%d'%(label,i) for i in range(num_class)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "sex\n",
      "====================\n",
      "[0]\ttrain-logloss:0.584476\n",
      "Will train until train-logloss hasn't improved in 25 rounds.\n",
      "[100]\ttrain-logloss:0.173959\n",
      "[200]\ttrain-logloss:0.120434\n",
      "[300]\ttrain-logloss:0.099464\n",
      "[400]\ttrain-logloss:0.088741\n",
      "[500]\ttrain-logloss:0.082435\n",
      "[600]\ttrain-logloss:0.078354\n",
      "[700]\ttrain-logloss:0.075506\n",
      "[783]\ttrain-logloss:0.073711\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "label = 'sex'\n",
    "print('='*20)\n",
    "print(label)\n",
    "print('='*20)\n",
    "y = y_sex\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"booster\": \"gblinear\",\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"eta\": 0.001,\n",
    "    \"silent\": 1,\n",
    "    \"lambda\":0,\n",
    "    \"alpha\": 0.05,\n",
    "}\n",
    "if 'tr' in task:\n",
    "    for tr,va in StratifiedShuffleSplit(y,n_iter=1,test_size=0.2,random_state=1):\n",
    "        X_tr = X_sp[tr]\n",
    "        y_tr = y[tr]\n",
    "        X_va = X_sp[va]\n",
    "        y_va = y[va]\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_tr, y_tr)\n",
    "    dvalid = xgb.DMatrix(X_va, y_va)\n",
    "\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    bst = xgb.train(params, dtrain, 1000, evals=watchlist,\n",
    "                    early_stopping_rounds=25, verbose_eval=20)\n",
    "    print(\"tr finish!\")\n",
    "if 'sub' in task:\n",
    "    n_iter = 784\n",
    "    dtrain = xgb.DMatrix(X_all_sp[:TR], y)\n",
    "    dtest = xgb.DMatrix(X_all_sp[TR:])\n",
    "\n",
    "    watchlist = [(dtrain, 'train')]\n",
    "    bst = xgb.train(params, dtrain, n_iter, evals=watchlist,\n",
    "                    early_stopping_rounds=25, verbose_eval=100)\n",
    "\n",
    "    _prd = bst.predict(dtest)\n",
    "    prd = np.zeros((len(_prd),2))\n",
    "    prd[:,1] = _prd\n",
    "    prd[:,0] = 1 - prd[:,1]\n",
    "    prds.append(prd)\n",
    "if 'stack' in task:\n",
    "    n = 5\n",
    "    n_iter = 784\n",
    "    num_class = 1\n",
    "    stack_tr = np.zeros((TR,num_class))\n",
    "    stack_te = np.zeros((TE,num_class))\n",
    "    dtest = xgb.DMatrix(X_all_sp[TR:])\n",
    "    for i,(tr,va) in enumerate(StratifiedKFold(y,n_folds=n)):\n",
    "        print('stack:%d/%d'%(i+1,n))\n",
    "        dtr = xgb.DMatrix(X_sp[tr],y[tr])\n",
    "        dva = xgb.DMatrix(X_sp[va],y[va])\n",
    "        bst = xgb.train(params, dtr, n_iter)\n",
    "        stack_tr[va] = bst.predict(dva).reshape(-1,1)\n",
    "        stack_te += bst.predict(dtest).reshape(-1,1)\n",
    "    stack_te /= n\n",
    "    stack = np.vstack([stack_tr,stack_te])\n",
    "    stacks.append(stack)\n",
    "    stacks_name += ['%s_%d'%(label,i) for i in range(num_class)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "loc\n",
      "====================\n",
      "[0]\ttrain-mlogloss:1.66761\n",
      "Will train until train-mlogloss hasn't improved in 25 rounds.\n",
      "[100]\ttrain-mlogloss:0.443336\n",
      "[200]\ttrain-mlogloss:0.384396\n",
      "[300]\ttrain-mlogloss:0.357345\n",
      "[400]\ttrain-mlogloss:0.340192\n",
      "[433]\ttrain-mlogloss:0.335917\n"
     ]
    }
   ],
   "source": [
    "#####################################################################\n",
    "#bst\n",
    "############################\n",
    "#鍦扮偣鐨勯娴嬪 sublinear_tf 鏁忔劅\n",
    "############################\n",
    "label = 'loc'\n",
    "print('='*20)\n",
    "print(label)\n",
    "print('='*20)\n",
    "y = y_loc\n",
    "params = {\n",
    "    \"objective\": \"multi:softprob\",\n",
    "    \"booster\": \"gblinear\",\n",
    "    \"num_class\":8,\n",
    "    \"eval_metric\": \"mlogloss\",\n",
    "    \"eta\": 0.01,\n",
    "    \"silent\": 1,\n",
    "    \"lambda\":0,\n",
    "    \"alpha\": 0.1,\n",
    "}\n",
    "if 'tr' in task:\n",
    "    for tr,va in StratifiedShuffleSplit(y,n_iter=1,test_size=0.4,random_state=1):\n",
    "        X_tr = X_sp[tr]\n",
    "        y_tr = y[tr]\n",
    "        X_va = X_sp[va]\n",
    "        y_va = y[va]\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_tr, y_tr)\n",
    "    dvalid = xgb.DMatrix(X_va, y_va)\n",
    "\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    bst = xgb.train(params, dtrain, 1000, evals=watchlist,\n",
    "                    early_stopping_rounds=25, verbose_eval=20)\n",
    "    prds.append(bst.predict(dtest))\n",
    "if 'sub' in task:\n",
    "    n_iter = 434\n",
    "    dtrain = xgb.DMatrix(X_all_sp[:TR], y)\n",
    "    dtest = xgb.DMatrix(X_all_sp[TR:])\n",
    "\n",
    "    watchlist = [(dtrain, 'train')]\n",
    "    bst = xgb.train(params, dtrain, n_iter, evals=watchlist,\n",
    "                    early_stopping_rounds=25, verbose_eval=100)\n",
    "    prds.append(bst.predict(dtest))\n",
    "if 'stack' in task:\n",
    "    n_iter = 434\n",
    "    n = 5\n",
    "    num_class = 8\n",
    "    stack_tr = np.zeros((TR,num_class))\n",
    "    stack_te = np.zeros((TE,num_class))\n",
    "    dtest = xgb.DMatrix(X_all_sp[TR:])\n",
    "    for i,(tr,va) in enumerate(StratifiedKFold(y,n_folds=n)):\n",
    "        print('stack:%d/%d'%(i+1,n))\n",
    "        dtr = xgb.DMatrix(X_sp[tr],y[tr])\n",
    "        dva = xgb.DMatrix(X_sp[va],y[va])\n",
    "        bst = xgb.train(params, dtr, n_iter)\n",
    "        stack_tr[va] = bst.predict(dva)\n",
    "        stack_te += bst.predict(dtest)\n",
    "    stack_te /= n\n",
    "    stack = np.vstack([stack_tr,stack_te])\n",
    "    stacks.append(stack)\n",
    "    stacks_name += ['%s_%d'%(label,i) for i in range(num_class)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub finish!\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "if 'sub' in task:\n",
    "    df_sub = pd.DataFrame()\n",
    "    df_sub['uid'] = df_mge.iloc[TR:]['uid']\n",
    "    n = len(df_sub)\n",
    "    df_sub['age'] = age_le.inverse_transform(prds[0].argmax(axis=1))\n",
    "    df_sub['gender'] = sex_le.inverse_transform(prds[1].argmax(axis=1))\n",
    "    df_sub['province'] = loc_le.inverse_transform(prds[2].argmax(axis=1))\n",
    "    df_sub.to_csv('../data/final1.csv',index=None)\n",
    "    print('sub finish!')\n",
    "    \n",
    "if 'stack' in task:\n",
    "    print(\"begin\")\n",
    "    stacks = np.hstack(stacks)\n",
    "    stacks = pd.DataFrame(data=stacks,columns=stacks_name)\n",
    "    stacks.to_csv('../data/newfeat/stack_new.csv',index=None)\n",
    "    print('stack finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
